\documentclass{acm_proc_article-sp-sigmod07}

\begin{document}
\title{RESTRUCTOR: Performing queries on structurally heterogeneous
dataspaces}
\author{Sartori Enrico}
\maketitle

\begin{abstract}
This work presents a framework, called RESTRUCTOR, which permits to
perform queries on dataspaces characterized by structural heterogeneity.
The system implemented builds a relational representation of the relevant
informations contained in the dataset and uses this model for performing
queries.

The proposed model deals with differences at the structural level of the
data, but not with the different syntactic representation of semantically
equivalent attributes.

This work describes in details the model used to represent the data, and
the techniques used for the extraction of the query results from the
dataspace.
\end{abstract}

\section{INTRODUCTION}
A relevant part of the data in some particular environments as, for
example, the internet, is characterized by a lack of a structure useful
to perform queries and give a semantical meaning to the informations
handled.

In a similar environment the data are considered to be a list of
identifiers with attached a set of pairs of the form (attribute name,
value). This basilar structure can be more complex, with nested
representation of the data.

The aim of this work is to provide a system which can convert this simple
structure in a relational model which can be used for performing queries.
The main idea on which the implemented approach is based is the
realization of two different structures: one for the storage of the data
and a second, used for resolving the dependencies between attributes
discovered in the dataset.

The query task is accomplished by retrieving all the attributes linked to
the one asked, through a lookup in the attributes structure.Then the
retrieved attributes are compared with the value given, using the storage
structure.

The system implemented performs these operation by creating in a
relational database a schema which can host this model, and using this
representation for executing the queries.
The interface exposed to the user accepts a simple query language, whose
details will be presented later.

Some assumption, like the way used for identifier specification and the
language used for the implementation will be clarified in following
sections.

\section{RELATED WORK}
One of the works which covers in major details the handling with
heterogeneous datasets is \cite{kaufmann:integration}. This work gives a panoramic
view on many different cases which can be encountered in data integration.

The scope of this work is wider than the one of this paper, in fact, it
presents techniques used for solving more general problems, like syntactic
differences in the data representation models to integrate.

Anyway it presents many approaches for identifying dependencies among
attributes from different databases, these techniques can be useful even
in the case of structural differences in the same database.

This section of the work present three different groups of approaches:
semantic based, object oriented or logic based.
For each of these groups, many different approaches are presented.
The approaches which are nearer to what is the aim of this paper are the
semantical and the object oriented models.

Another important section of this work describes how to deal with the
problem of the effective generation of the integrated schema.

More close to the problem addressed in this paper is the technique
presented in \cite{dong:indexing}.
In fact this work addresses the specific problem of performing queries
over a dataspace characterized by being partially unstructured and
heterogeneous.

The solution provided by Dong and Halevy is the building of an indexing
structure, which can be used for accessing the data matching the given
query.

The indexing structure presented in the paper, is stored in form of
relational model, which permits to specify which entity owns some
particular attributes.

\section{PROBLEM STATEMENT}
As said in the introduction the aim of this work is to provide support for
performing queries over dataspaces presenting differences in the structure
used for data representation.
The system implemented doesn't deal with differences at a syntactic level,
in fact it relies on the equality of attributes name for the
identification of relations among attributes.

Possible examples of heterogeneousness in data representation that the
system can handle are in the form of the following examples:

\begin{verbatim}
entity 1
    city : molveno
    street : paganella

entity 2
    address :
        city : molveno
        street : paganella

entity 3
    address : molveno paganella 
\end{verbatim}

These three entities refers to the same real object, in fact the data
contained is semantically equivalent, but it's represented using three
different structures.

It's not possible to query directly a similar database, in fact there is
no direct correspondence between attributes from different entities.
For a human reader, is anyway clear how city and street are components of
the attribute address. This relation has to be considered when, for
example, an user asks for the entities with attribute address associated
to a specific value.

The same is valid for the inverse case, e.g. when the user asks for the
attribute city even the entities with attribute address matching the query
specification has to be returned.

The model in the previous example can be made more complex by adding a new
entity like the following:

\begin{verbatim}
entity 4
    lives:
        address :
            city : molveno
            street : paganella
    
    works:
        city : trento
         
\end{verbatim}

Adding this case a new layer of inclusion is present, in fact now city
appears as member of address, but even as component of the attribute
lives. 

It appears clear that different kind of result should have a different
weight in the final result of the query. For this reason the system
associates different ranks to entities returned in the different cases.

Obviously a higher rank is given to an entity returned in case of exact
correspondence of the name and the value of the attribute searched.
Results retrieved by looking for correspondences in the linked attributes,
instead, are ranked with a lower value.

Summarizing what said before, is possible to identify three main aspects
of the problem to solve:
\begin{itemize}
\item Insertion of the data in the relational model;
\item Performing queries on the model created;
\item Rank and organize the results;
\end{itemize}

\section{PROPOSED APPROACH}
This section of the paper presents in further details the approach
followed for giving a solution to the problem targeted. It will cover the
three aspects introduced previously.

In order to ease the implementation task is assumed that the input of the
program, the database to be analyzed, is represented by an xml file, with
no DTD attached. The root of the document is a tag entities which
contains a set of tags entity which represent an entry of the database.
Each tag entity has an unique attribute id which identifies an entry.

An example input could be the following:

\begin{verbatim}
<entities>
    <entity id="1">
        <city>trento</city>
        <street>sommarive</street>
    </entity>
</entities>
\end{verbatim}

Another possible way to represent the input could be using the JSON
syntax, which could be more appropriate than xml for representing
unstructured data. The common xml syntax has been preferred due to the
wider selection of tools for parsing and operate on this language.

The advantages in using JSON could be represented by a more lightweight
database and the use of a syntax more data-oriented, which fit better the
situation of an unstructured dataspace.

The assumption on the identifiers position in the xml has been taken for
simplifying the parsing task, and focus more attention on retrieving the
relevant information from the database. This choice doesn't influence the
accuracy of the query answering algorithm.

\subsection{Relational Model}
This section introduced the details of the structure used to store the
data and perform the queries. As said before, the data are stored in a
relational database. 

The importance of relying on a database engine for storing and handling the
data has a major importance in terms of performances. In fact a DBMS
integrates a set of optimization algorithms and caching routines which can
help maintaining the performances of the system at a good level.

The base idea of the approach followed is to extract from the database two
different kind of information. An entity in the dataspace, in fact,
contains relevant information about itself, specified by the pairs
(name, value), but it gives information even about the structure of the
data, on how different attributes relate with each other.

An example of this can be seen in the following code:

\begin{verbatim}
<entity id="1">
    <car>
        <model>punto</model>
        <brand>fiat</brand>
    </car>
</entity>
\end{verbatim}

This entity in fact contains an element car which is composed by two
different attributes, model and brand. Appears clear that exists a
relation between the attribute model and car and between brand and car.
The information that we can extract from this, about the structure of the
data, is that the attributes model and brand can appear in the dataset as
children of the attribute car.

This kind of information is vital for the query answering task, in fact,
using this prior knowledge we can return as a result for a query asking
for entities with car = fiat even the following example: 

\begin{verbatim}
<entity id="2">
    <model>punto</model>
    <brand>fiat</brand>
</entity>
\end{verbatim}

This entity doesn't refer explicitly to the car attribute, but the prior
knowledge about the structure of the dataset gives the possibility to
reach an higher accuracy for the query results.
Obviously the relevance of this entity as a result of the query car = fiat
is not the same as the one of the previous entry.

The model implemented for dealing with this kind of information is
composed by three tables. The first one is used for the storage of the
effective data, is called "pairs" and its structure is defined on three
fields:
\begin{description}
\item{pair\_id: } This is the primary key of the table, identifies a pair;
\item{name: } This field contains the name of the attribute;
\item{value: } Contains the respective value;
\end{description}

This table is populated with all the different pairs (attribute name,
attribute value) encountered reading the dataset. At each pair is
associated an unique id which is pair\_id.

The name of the attribute doesn't contain any information about its path
in the entity representation.

An important constraint set in this table is that the pairs name and value
are unique. This means that in the worst case, where there aren't
attributes with the same name and the same value among the whole database,
the table will contain a number of records equal to the number of pairs in
the original dataset.

Is likely, instead, that many entities share some pair, in this case the
shared pair will appear only one time in this table.

A second table is used for storing the information about the structure.
What is needed to be kept is some information about the position of the
attribute inside the attribute hierarchy of a specific entity.
In the model implemented the fields of this table, called "attrs" are:
\begin{description}
\item{attr\_id: } This is the primary key of the table, identifies an
attribute;
\item{name: } This field contains the name of the attribute;
\item{path: } Contains the path of the attribute from the entity node;
\end{description}

The term path doesn't refer specifically to the xml concept of path, but
in general to the attribute is nested inside some other attributes.
The same concept would work with any other representation of the dataset,
instead of xml.

Using this table is possible to reconstruct the underlying structure of
the database, and identify every different attribute present in the
dataset.

Is important to notice that this table contains only the attributes which,
appear at least one time in the database with a value associated.
If an attribute appears only as parent of other attributes in the whole
dataset, it won't appear in this table.

Even in this case the path is an unique field, so attributes with
identical structure will appear only one time in the table.

The last table permits to combine the information in the previous two
tables.
In fact the third table, called "associations" contains the following
fields:
\begin{description}
\item{entity\_id: } This fields contain the id of the entity which owns
the pair;
\item{pair\_id: } This is the id of the pair owned, refers to the pairs
table;
\item{attr\_id: } Indicates which particular attribute forms the pair,
refers to the attrs table;
\end{description}

This table links the information on the data with the knowledge about the
structure. Is therefore possible to know exactly the particular attributes
which form every pair of an entity, and the associated value.

This is the table which present the larger number of records of the three,
in fact it will contain one row for each pair encountered in the dataset.

\subsection{Query language}
Before going in further details about the query answering techniques, is
useful to specify the query languages used to interact with the system.

As seen in the previous sections, the information about the entities are
represented in form of pairs (name, value), for this reason even the
language used to express the queries should follow the same model.

Precisely a query is represented by a list of expression in the form
``attribute name : attribute value'' separated by a `,' character.
So, for example, the following expression is a valid query: 

\begin{verbatim}
city : trento, street : sommarive
\end{verbatim}

The result of this query will be the list of the entities which satisfy
both the element of the query.
This because the concatenation of the elements is considered as a logical
AND between the conditions.
The language can accept an arbitrary number of conditions for a single
query.

\subsection{Populating the Model}
The first task performed by the system is to read the input dataset and
populate the model with the needed data.
This operation is done by the Parser class, which parse the xml
representation of the dataset and stores the data in the relative tables.

When a new entity is encountered the names and the values of all its
attributes are stored in the table `pairs', as said before this table
doesn't admit duplicates, so it will accept only pairs which appears for
the first time in the dataset.

For each attribute encountered the system needs to store informations
about the structure of the data, so it will insert in the `attributes'
table a tuple containing the name and the path of the attribute.
Even this table does not permit duplicated values, so a new tuple will be
added only if represent a new kind of attribute.

Another behaviour to be considered is when a composed attribute is
encountered, for example the following:

\begin{verbatim}
<entity id="1">
    <address>trento via sommarive 14</address>
</entity>
\end{verbatim}

In this case many different informations, like city, street or number, are
collapsed in the only address attribute. The platform deals with this kind
of attributes dividing the value in single words and treating them as
different values of the attribute address. An xml representation of the
obtained values would be the following:

\begin{verbatim}
<entity id="1">
    <address>trento</address>
    <address>via</address>
    <address>sommarive</address>
    <address>14</address>
</entity>
\end{verbatim}

Finally the third table, the `associations' one, is populated. A tuple of
this table contains the id of an entity, the id of a pair and the id of an
attribute structure. The meaning of this association is to tell which
particular attributes (with their relative structure) belongs to an entity
and what values they take.

In order to have a clearer idea of the functioning of the model is useful
to have a concrete example.
The following xml code represents the dataset:

\begin{verbatim}
<entities>
    <entity id="1">
        <car>fiat punto</car>
    </entity>
    <entity id="2">
        <car>
            <model>panda</model>
            <brand>fiat</brand>
        </car>
    </entity>
    <entity id="3">
        <brand>ford</brand>
        <model>puma</model>
        <color>red</color>
    </entity>
</entities>
\end{verbatim}

After the input processing the tuples contained in the table pairs will be
the same of the table \ref{tabp1}.

\begin{table}
\begin{tabular}{|c|l|l|}
\hline
pair\_id & name & value \\
\hline
1 & car & fiat \\ 
2 & car & punto \\
3 & model & panda \\ 
4 & brand & fiat \\
5 & brand & ford \\
6 & model & puma \\
7 & color & red \\
\hline
\end{tabular}
\caption{Content of table `pairs'}
\label{tabp1}
\end{table}

The table attrs, instead will contain the structural information
about the dataset, so it will contain these tuples as reported in table
\ref{tabat1}.

\begin{table}
\begin{tabular}{|c|l|l|}
\hline
attr\_id & name & path \\
\hline
1 & car   & /car/ \\
2 & model & /car/model/ \\
3 & brand & /car/brand/ \\
4 & brand & /brand/ \\
5 & model & /model/ \\
6 & color & /color/ \\ 
\hline
\end{tabular}
\caption{Content of table `attrs'}
\label{tabat1}
\end{table}

The table associations, will link the information contained in the
previous tables, permitting to understand which are the attributes owned
by the various entities. Its data will be like the one in table
\ref{tabas1}.

\begin{table}
\begin{tabular}{|c|l|l|}
\hline
entity\_id & pair\_id & attr\_id \\
\hline
1 & 1 & 1 \\
1 & 2 & 1 \\
2 & 3 & 2 \\
2 & 4 & 3 \\
3 & 5 & 4 \\
3 & 6 & 5 \\
3 & 7 & 6 \\
\hline
\end{tabular}
\caption{Content of table `associations'}
\label{tabas1}
\end{table}

\subsection{Query Answering}
This part of the system uses the relational model defined before in order
to answer to the queries asked by the user.
The answer to a query is a combination of various interrogation to the
relational database.

The objective of the queries are to retrieve the identities which satisfy
the condition posed, searching them across the structural differences
among the various entries.
In order to reconstruct the underlying structure of the dataset the system
selects the following families of attributes:
\begin{itemize}
\item Attributes which presents exact correspondence with the name of the
asked one;
\item Attributes which appears in the dataset as child of the one asked;
\item Attributes which appears in the database as parent of the one asked;
\end{itemize}

The first category of attributes can be queried looking directly in the
pairs and associations tables, in fact through this second table is
possible to retrieve the identities which own the asked pair.

The table `attrs' is needed to resolve the other two kinds of attributes,
in fact the path is needed to retrieve the child of the selected attribute
and to resolve its parents.

It's important to notice that in this two cases we can find two different
situations.
In fact considering the previous example can be noticed that the attribute
car appears in the dataset as composed by the attributes model and brand. 
So if the user asks for the attribute car, the system looks even for the
child attributes, which appear obviously as child of car but
even independently in the dataset.

Appears clear that these two different kind of attributes will have
different weights when computing the final result list.

The technique used in this platform is to retrieve the identifiers of all
the attributes whose path contains the name of the attribute asked.
In this way is possible to retrieve all the attributes which appears as
child of the asked one in the dataset.

Instead, is the names of the attributes are retrieved, rather than the
ids, is possible to retrieve this kind of attributes even in the situation
where they don't appear as child of the attribute asked. Like, referring
to the previous example, when model and brand, which are known to be child
of car, appear at the root level, as in entity 3.

As remarked before the possibility to distinguish between these two cases
is important to associate an appropriate weight to these queries.

The inverse case, when the system looks for the parent of the attribute
selected, is handled in similar way.
In fact, for all the attributes whose name is equal to the one requested
the system retrieves all the attribute which appear in the path.
In this way is possible obtain a list of all the attributes which appears
as parent of the one chosen.

In order to retrieve the name of the attributes from the path it could
have been possible to parse the string corresponding to the path and
isolate the single names.
This technique, besides being simple, has a drawback. In fact it would
produce a list containing even the attributes which have no value attached
in the whole dataset, but they appear always as parent of some other
attribute.

This could lead to waste time performing queries that will give no
results. The technique used here is to compare the name of the attributes
selected from the pairs table with the paths retrieved previously. In this
way all the attributes obtained will surely have a value attached.

\subsection{Results Reporting}
The last operation performed by RESTRUCTOR, is to report the results of
the queries operated. This means, specifically, that not all the entities
returned have the same value with respect to the query asked.

Always referring to the cars dataset presented before, if the user submits
the query ``brand:fiat'' the system will return the entities 1 and 2.
But, as is possible to evince from the xml file, entity 2 has a perfect
correspondence between names and values of the attribute. Entity 1,
instead, is returned because the attribute brand appears as a child of 
attribute car, which is owned by this entity.

The relevance of the result ``entity 2'' is therefore higher than the
other one.

For dealing with this difference in result relevance, the system attaches
a rank value to the results belonging to the different families seen
before. In particular, the ranking scheme followed is the following:
\begin{itemize}
\item Exact correspondence between attribute names = 100
\item The entity owns an attribute as child of the one asked = 75
\item The entity owns an attribute which is parent of the one asked = 50
\item The entity owns an attribute, which is known to be a child of the
one asked, but in a free position = 25
\end{itemize}

As seen in the section about the query language, is possible to specify
more than one single condition per query. The total rank for a entity,
which must appear in the result of all the conditions, is the sum of rank
obtained in the single queries.

To the user, in order to give an intuitive idea of the relevance of his
results, the score is presented as the percentage of ``points'' scored
over the total available.

For example, the query ``car : fiat, model : panda''  asked over the cars
dataset will give as result the entity 2 with relevance of 87.5\%.
In fact this entity has the attribute model that gives a rank of 100, and
the attribute brand, which is a known child of car, therefore its rank is
75. The sum is 175, which corresponds to the 87,5\% of the maximum rank.

From a lower level perspective, this attribution of the ranking is
performed through the creation of a temporary table which contains the
results of the different queries performed.
The fields of this table are the following:

\begin{description}
\item{entity\_id: } The id of an entity which satisfies one of the
condition of the query.
\item{rank: } The rank associated to the family of the attribute which
satisfies the query condition
\item{num: } An identifier for the condition satisfied by the entity
\end{description}

The results of the single queries are directly stored in this table with
the needed information attached. Then the system selects from this table
all the entities which satisfies all the condition expressed, sums the
ranks obtained and outputs the results with the percentage representing
the relevance.

\subsubsection{Special case}
The system can handle a particular case in results reporting, in fact in
can happen that a single entity appears more time among the results of a
single query.
An example can clarify this sentence:

\begin{verbatim}
<entity id="1">
    <lives>
        <address>
            <city>molveno</city>
            <street>paganella</street>
            <number>23</number>
        </address>
    </lives>
    <works>
        <address>paganella</address>
    </works>
</entity>
\end{verbatim}

If the user asks the query ``street : paganella'', the entity 1 is
returned with rank 100 because of the exact correspondence between the
street attribute.
But this entity contains even an address attribute, which appears as
parent of street in the dataset, for this reason the same entity is
returned a second time, this time with rank 50, for a single query.

The total measure of relevance will show a good 150\%, which obviously
should be not considered a valid result.
In order to prevent this kind of issues the result table is grouped by the
entity id and the number of the query before computing the relevance.
In this way the platform avoids having the same entity appearing more time
among the results of a single query.

The rank used is the higher obtained in case of multiple appearances in a
single query.
In the example reported before, the rank for the entity 1 for this query
would be 100, because it's the maximum value reached.

\section{TESTING}
The test of the project has been directed in two main directions: to study
the behaviour of the system in particular situation, and, otherwise test
the platform on larger datasets.

To test large datasets a little python script has been developed inside
the project, the goal of this software is to generate a large dataset.
During testing has been used datasets with maximum 100000 entities with 3
or 4 attributes for each.

This tests has shown how the operation which takes more time is to parse
the dataset and populate the relational model with the data. The time
taken to answer the queries, remains usually very low.
In fact the system is designed to rely deeply on a database engine, and
avoids to retrieve data from the database to perform analysis.

The technique used, instead, uses the instrument provided by the database
engine, and this contributes to keep the performances acceptable.






\bibliographystyle{abbrv}
\bibliography{report}
\end{document}
